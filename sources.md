# Sources
Additional Sources used for solving the tasks

## General Understanding of the Data
- [Liu, Z., & Cho, S. (2012, September). Characterizing machines and workloads on a Google cluster. In 2012 41st International Conference on Parallel Processing Workshops (pp. 397-403). IEEE.](https://www.xcg.cs.pitt.edu/papers/liu-srmpds12.pdf)

## Task 1
- [PySpark Where Filter Example](https://sparkbyexamples.com/pyspark/pyspark-where-filter/)
- [PySpark GroubBy Example](https://sparkbyexamples.com/pyspark/pyspark-groupby-count-explained/)
- [PySpark GroubBy Percentage Example](https://www.statology.org/pyspark-groupby-percentage/)
- [Pyspark Documentation SQL lit](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lit.html)
