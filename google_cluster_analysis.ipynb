{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ca1d07-9bb5-4e52-a485-7a16f8058a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# DATA_DIR_L =  \n",
    "# DATA_DIR = DATA_DIR_L\n",
    "\n",
    "DATA_DIR_M = \"/home/masa/Downloads/google-cloud-sdk/our_data\"\n",
    "DATA_DIR = DATA_DIR_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70a0f57-566f-453e-bb7d-0cbed2d78be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/23 09:28:31 WARN Utils: Your hostname, masa-VirtualBox, resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "25/12/23 09:28:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/23 09:28:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# We use spark session in order to use DataFrames\n",
    "ss = SparkSession.builder \\\n",
    "    .appName(\"GoogleClusterAnalysis\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec48b01-d6da-461e-b03d-d4375facac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99601e5-2160-470e-9fd6-781d4257e30d",
   "metadata": {},
   "source": [
    "### 1. What is the distribution of the machines according to their CPU capacity? Can you explain (motivate) it?\n",
    "\n",
    "https://www.researchgate.net/publication/261164671_Characterizing_Machines_and_Workloads_on_a_Google_Cluster\n",
    "\n",
    "TODO: add comments and conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9d4748-eb98-445e-a571-31be9808a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_schema = StructType([\n",
    "    StructField('time', LongType(), True),\n",
    "    StructField('machine_ID', LongType(), True),\n",
    "    StructField('event_type', IntegerType(), True),\n",
    "    StructField('platform_ID', StringType(), False),\n",
    "    StructField('CPUs', DoubleType(), False),\n",
    "    StructField('memory_capacity', DoubleType(), False),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b34477d-e7f6-4dad-baa7-6b9d62650944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+--------------------+----+---------------+\n",
      "|time|machine_ID|event_type|         platform_ID|CPUs|memory_capacity|\n",
      "+----+----------+----------+--------------------+----+---------------+\n",
      "|   0|         5|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|\n",
      "|   0|         6|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|\n",
      "|   0|         7|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|\n",
      "|   0|        10|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|\n",
      "|   0|        13|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|\n",
      "+----+----------+----------+--------------------+----+---------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_machines = ss.read.csv(os.path.join(DATA_DIR,\"machine_events/*.csv.gz\"), schema=machine_schema)\n",
    "df_machines.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9352de49-6000-4193-b4b3-914c2d6864c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "12583"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machines.select('machine_ID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebaead0-9aef-4acd-9f69-44e98e3689c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machines.select(\"event_type\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bb26c0-63f7-4f24-9cc3-81988184d3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "21443"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machines.filter(df_machines[\"event_type\"] == 0).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6215b33-9715-41aa-b174-87b86fa29d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "12477"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count_t0 = df_machines.filter(df_machines[\"time\"] == 0).distinct().count()\n",
    "total_count_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1331875-e635-4750-a1f8-ab973fc2dff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12477"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machines.select(\"machine_ID\").filter(df_machines[\"time\"] == 0).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6256ef8-59c3-4767-89ac-1249bf764c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|CPUs|\n",
      "+----+\n",
      "| 1.0|\n",
      "| 0.5|\n",
      "|0.25|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_machines.select(\"CPUs\").filter(df_machines[\"time\"] == 0).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f482af46-615d-455a-ae79-ca3c2d7d9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|CPUs|count|\n",
      "+----+-----+\n",
      "| 1.0|  791|\n",
      "| 0.5|11563|\n",
      "|0.25|  123|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ex1 = df_machines.select(['machine_ID', 'CPUs']).filter(df_machines[\"time\"] == 0).groupby('CPUs').count()\n",
    "df_ex1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054b3504-63b7-4d60-9a18-f7f52363c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+\n",
      "|CPUs|count|percentage|\n",
      "+----+-----+----------+\n",
      "| 1.0|  791|       6.0|\n",
      "| 0.5|11563|      93.0|\n",
      "|0.25|  123|       1.0|\n",
      "+----+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ex1.withColumn(\"percentage\", F.round((F.col(\"count\") / total_count_t0) * 100)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76aee57-5ce7-47a4-a1a7-5ed01305d16c",
   "metadata": {},
   "source": [
    "- at timestamp==0, there are 12477 machines intially started, and for them we want to  find the distribution (of those machines) acoording to their CPU capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbbee26-10c8-4a71-a347-359d81f2efa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2fa8fdf-fe2f-4680-858d-66e83b789eb6",
   "metadata": {},
   "source": [
    "### 2. What is the percentage of computational power lost due to maintenance (a machine went offline and reconnected later)? The computational power is proportional to both the CPU capacity and the unavailabil- ity period of machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b17edf-84db-4192-8856-872ea12f94a6",
   "metadata": {},
   "source": [
    "- event_type = 1 means that a machine was removed from the cluster. Removals can occur due to\n",
    "failures or maintenance\n",
    "- we want to find all the times machien was removed due to maintenance and then reconnected later (event_type=0 in a time step later than for the event_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3761a2fb-5b1c-4bf1-bab4-3e196d1970d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb7e57f7-d97c-4f60-9582-60f6566c873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "|        time|machine_ID|event_type|         platform_ID|CPUs|memory_capacity|next_event|   next_time|\n",
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "|           0|         5|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         1|835150655707|\n",
      "|835150655707|         5|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|836124903464|\n",
      "|836124903464|         5|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|      NULL|        NULL|\n",
      "|           0|         6|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|      NULL|        NULL|\n",
      "|           0|         7|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|      NULL|        NULL|\n",
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"machine_ID\").orderBy(\"time\")\n",
    "\n",
    "df_next = df_machines.withColumn(\"next_event\", F.lead(\"event_type\").over(window))\n",
    "df_next = df_next.withColumn(\"next_time\", F.lead(\"time\").over(window))\n",
    "\n",
    "df_next.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052d94bb-d5c0-480e-9942-686aca5c7208",
   "metadata": {},
   "source": [
    "- By partitioning the window by machine_id, we ensure that all events types are processed independently for **each machine**. In taht way, we are sure that event pairings will refer to the same physical machine\n",
    "\n",
    "- The lead() function returns the following event and time for the same machine. Previously, we ordered events by time, and therefore, \"next\" refers to the next chronological event in that machine's sequence of events. In that way, we can be sure that we are identifying distinct offline intervals without overlappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "321c0162-9600-4474-a87c-6c8d8a87076d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "|        time|machine_ID|event_type|         platform_ID|CPUs|memory_capacity|next_event|   next_time|\n",
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "|           0|        43|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         2|372991930737|\n",
      "|372991930737|        43|         2|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         2|373198072841|\n",
      "|373198072841|        43|         2|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         2|727861243083|\n",
      "|727861243083|        43|         2|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         2|736148630106|\n",
      "|736148630106|        43|         2|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         2|736768939531|\n",
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# this is just a check to see if time intervals are not overlapping, and if event types are matching\n",
    "df_next.filter(df_reloaded[\"machine_ID\"] == 43).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af2e6a-cc0d-4697-8f06-973a10de337a",
   "metadata": {},
   "source": [
    "- Now, we want to filter df_next to reflect only situations when machine went offline and was reloaded afterwards. That can be achieved by observing **event_type=1** followed by **next_event=0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d7a8431d-1ade-4b0b-b472-51dc5a9bb3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8860"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reloaded = df_next.filter((df_next[\"event_type\"]==1) & (df_next[\"next_event\"]==0))\n",
    "df_reloaded.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc717a-f2e2-40bb-998b-d772edd09bcb",
   "metadata": {},
   "source": [
    "- We notice that this number matches the number of such observed cases of reloaded machines that were mentioned in paper: https://www.researchgate.net/publication/261164671_Characterizing_Machines_and_Workloads_on_a_Google_Cluster  on page 3 (Figure 3) which tells us we're on good trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b711cdfd-8691-4357-9f05-56dc4ff71251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+----+---------------+----------+-----------+\n",
      "|machine_ID|event_type|         platform_ID|CPUs|memory_capacity|next_event|      dtime|\n",
      "+----------+----------+--------------------+----+---------------+----------+-----------+\n",
      "|         5|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  974247757|\n",
      "|        10|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  998726348|\n",
      "|        13|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  997280215|\n",
      "|        23|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  120851153|\n",
      "|        26|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|88666880740|\n",
      "+----------+----------+--------------------+----+---------------+----------+-----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Here we just extract offline time in a column named \"dtime\"\n",
    "df_reloaded = df_reloaded.withColumn(\"dtime\", F.col(\"next_time\").cast(\"long\")-F.col(\"time\").cast(\"long\")).drop(\"time\", \"next_time\")\n",
    "df_reloaded.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d15b4460-0ff0-49bf-8f88-f51cba8e037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80273246292457.75"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we want to calculate lost resources for each sample as a product of offline time and CPUs, and then we sum over all samples\n",
    "df_reloaded = df_reloaded.withColumn(\"lost\", df_reloaded[\"dtime\"]*df_reloaded[\"CPUs\"])\n",
    "total_lost = df_reloaded.agg(F.sum(\"lost\")).collect()[0][0]\n",
    "total_lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "451daaf0-2861-4c69-97d3-fb993abe3eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, in order to find percentage of lost resources, we want to find possible total power\n",
    "total_cpu = df_machines.select(\"machine_ID\", \"CPUs\").agg(F.sum(\"CPUs\")).collect()[0][\"sum(CPUs)\"]\n",
    "trace_bounds = df_machines.agg(\n",
    "    F.min(\"time\").alias(\"start\"),\n",
    "    F.max(\"time\").alias(\"end\")\n",
    ").collect()[0]\n",
    "total_time = trace_bounds[\"end\"] - trace_bounds[\"start\"]\n",
    "\n",
    "total_power = total_cpu * total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b7e714f4-9fd4-4219-a6f2-755d66423ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of computational power lost due to maintenance: 0.1613%\n"
     ]
    }
   ],
   "source": [
    "percentage_lost = total_lost/total_power * 100\n",
    "print(f\"Percentage of computational power lost due to maintenance: {percentage_lost:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f6a55-b8a4-4905-af59-f3a7e789b7d8",
   "metadata": {},
   "source": [
    "- Here, we conclude that the total percentage of computational power lost due to mainenance is 0.16%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3deb58e-46ea-4dc4-ad8b-1cb80d12d6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
