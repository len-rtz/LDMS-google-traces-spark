{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ca1d07-9bb5-4e52-a485-7a16f8058a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "DATA_DIR_L =  \"\"\n",
    "# DATA_DIR = DATA_DIR_L\n",
    "\n",
    "DATA_DIR_M = \"/home/masa/Downloads/google-cloud-sdk/our_data\"\n",
    "DATA_DIR = DATA_DIR_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70a0f57-566f-453e-bb7d-0cbed2d78be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use spark session in order to use DataFrames\n",
    "ss = SparkSession.builder \\\n",
    "    .appName(\"GoogleClusterAnalysis\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec48b01-d6da-461e-b03d-d4375facac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99601e5-2160-470e-9fd6-781d4257e30d",
   "metadata": {},
   "source": [
    "### 1. What is the distribution of the machines according to their CPU capacity? Can you explain (motivate) it?\n",
    "\n",
    "https://www.researchgate.net/publication/261164671_Characterizing_Machines_and_Workloads_on_a_Google_Cluster\n",
    "\n",
    "TODO: add comments and conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9d4748-eb98-445e-a571-31be9808a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_schema = StructType([\n",
    "    StructField('timestamp', LongType(), True),\n",
    "    StructField('machine_ID', LongType(), True),\n",
    "    StructField('event_type', IntegerType(), True),\n",
    "    StructField('platform_ID', StringType(), False),\n",
    "    StructField('CPUs', DoubleType(), False),\n",
    "    StructField('memory_capacity', DoubleType(), False),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b34477d-e7f6-4dad-baa7-6b9d62650944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+--------------------+----+---------------+\n",
      "|timestamp|machine_ID|event_type|         platform_ID|CPUs|memory_capacity|\n",
      "+---------+----------+----------+--------------------+----+---------------+\n",
      "|        0|         5|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|\n",
      "|        0|         6|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|\n",
      "|        0|         7|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|\n",
      "|        0|        10|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|\n",
      "|        0|        13|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|\n",
      "+---------+----------+----------+--------------------+----+---------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_machines = ss.read.csv(os.path.join(DATA_DIR,\"machine_events/*.csv.gz\"), schema=machine_schema)\n",
    "df_machines.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9352de49-6000-4193-b4b3-914c2d6864c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "12583"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machines.select('machine_ID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebaead0-9aef-4acd-9f69-44e98e3689c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machines.select(\"event_type\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bb26c0-63f7-4f24-9cc3-81988184d3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21443"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machines.filter(df_machines[\"event_type\"] == 0).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6215b33-9715-41aa-b174-87b86fa29d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12477"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count_t0 = df_machines.filter(df_machines[\"timestamp\"] == 0).distinct().count()\n",
    "total_count_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1331875-e635-4750-a1f8-ab973fc2dff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12477"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machines.select(\"machine_ID\").filter(df_machines[\"timestamp\"] == 0).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6256ef8-59c3-4767-89ac-1249bf764c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|CPUs|\n",
      "+----+\n",
      "| 1.0|\n",
      "| 0.5|\n",
      "|0.25|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_machines.select(\"CPUs\").filter(df_machines[\"timestamp\"] == 0).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f482af46-615d-455a-ae79-ca3c2d7d9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|CPUs|count|\n",
      "+----+-----+\n",
      "| 1.0|  791|\n",
      "| 0.5|11563|\n",
      "|0.25|  123|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ex1 = df_machines.select(['machine_ID', 'CPUs']).filter(df_machines[\"timestamp\"] == 0).groupby('CPUs').count()\n",
    "df_ex1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054b3504-63b7-4d60-9a18-f7f52363c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+\n",
      "|CPUs|count|percentage|\n",
      "+----+-----+----------+\n",
      "| 1.0|  791|       6.0|\n",
      "| 0.5|11563|      93.0|\n",
      "|0.25|  123|       1.0|\n",
      "+----+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ex1.withColumn(\"percentage\", F.round((F.col(\"count\") / total_count_t0) * 100)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76aee57-5ce7-47a4-a1a7-5ed01305d16c",
   "metadata": {},
   "source": [
    "- at timestamp==0, there are 12477 machines intially started, and for them we want to  find the distribution (of those machines) acoording to their CPU capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbbee26-10c8-4a71-a347-359d81f2efa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2fa8fdf-fe2f-4680-858d-66e83b789eb6",
   "metadata": {},
   "source": [
    "### 2. What is the percentage of computational power lost due to maintenance (a machine went offline and reconnected later)? The computational power is proportional to both the CPU capacity and the unavailabil- ity period of machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b17edf-84db-4192-8856-872ea12f94a6",
   "metadata": {},
   "source": [
    "- event_type = 1 means that a machine was removed from the cluster. Removals can occur due to\n",
    "failures or maintenance\n",
    "- we want to find all the times machien was removed due to maintenance and then reconnected later (event_type=0 in a time step later than for the event_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3761a2fb-5b1c-4bf1-bab4-3e196d1970d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb7e57f7-d97c-4f60-9582-60f6566c873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "|   timestamp|machine_ID|event_type|         platform_ID|CPUs|memory_capacity|next_event|   next_time|\n",
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "|           0|         5|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         1|835150655707|\n",
      "|835150655707|         5|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|836124903464|\n",
      "|836124903464|         5|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|      NULL|        NULL|\n",
      "|           0|         6|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|      NULL|        NULL|\n",
      "|           0|         7|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|      NULL|        NULL|\n",
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"machine_ID\").orderBy(\"timestamp\")\n",
    "\n",
    "df_next = df_machines.withColumn(\"next_event\", F.lead(\"event_type\").over(window))\n",
    "df_next = df_next.withColumn(\"next_time\", F.lead(\"timestamp\").over(window))\n",
    "\n",
    "df_next.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052d94bb-d5c0-480e-9942-686aca5c7208",
   "metadata": {},
   "source": [
    "- By partitioning the window by machine_id, we ensure that all events types are processed independently for **each machine**. In that way, we are sure that event pairings will refer to the same physical machine\n",
    "\n",
    "- The lead() function returns the following event and time for the same machine. Previously, we ordered events by timestamp, and therefore, \"next\" refers to the next chronological event in that machine's sequence of events. In that way, we can be sure that we are identifying distinct offline intervals without overlappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "321c0162-9600-4474-a87c-6c8d8a87076d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "|   timestamp|machine_ID|event_type|         platform_ID|CPUs|memory_capacity|next_event|   next_time|\n",
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "|           0|        43|         0|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         2|372991930737|\n",
      "|372991930737|        43|         2|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         2|373198072841|\n",
      "|373198072841|        43|         2|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         2|727861243083|\n",
      "|727861243083|        43|         2|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         2|736148630106|\n",
      "|736148630106|        43|         2|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         2|736768939531|\n",
      "+------------+----------+----------+--------------------+----+---------------+----------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# this is just a check to see if time intervals are not overlapping, and if event types are matching\n",
    "df_next.filter(df_next[\"machine_ID\"] == 43).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af2e6a-cc0d-4697-8f06-973a10de337a",
   "metadata": {},
   "source": [
    "- Now, we want to filter df_next to reflect only situations when machine went offline and was reloaded afterwards. That can be achieved by observing **event_type=1** followed by **next_event=0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7a8431d-1ade-4b0b-b472-51dc5a9bb3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8860"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reloaded = df_next.filter((df_next[\"event_type\"]==1) & (df_next[\"next_event\"]==0))\n",
    "df_reloaded.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc717a-f2e2-40bb-998b-d772edd09bcb",
   "metadata": {},
   "source": [
    "- We notice that this number matches the number of such observed cases of reloaded machines that were mentioned in paper: https://www.researchgate.net/publication/261164671_Characterizing_Machines_and_Workloads_on_a_Google_Cluster  on page 3 (Figure 3) which tells us we're on good trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b711cdfd-8691-4357-9f05-56dc4ff71251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+----+---------------+----------+-----------+\n",
      "|machine_ID|event_type|         platform_ID|CPUs|memory_capacity|next_event|      dtime|\n",
      "+----------+----------+--------------------+----+---------------+----------+-----------+\n",
      "|         5|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  974247757|\n",
      "|        10|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  998726348|\n",
      "|        13|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  997280215|\n",
      "|        23|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  120851153|\n",
      "|        26|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|88666880740|\n",
      "+----------+----------+--------------------+----+---------------+----------+-----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Here we just extract offline time in a column named \"dtime\"\n",
    "df_reloaded = df_reloaded.withColumn(\"dtime\", F.col(\"next_time\").cast(\"long\")-F.col(\"timestamp\").cast(\"long\")).drop(\"timestamp\", \"next_time\")\n",
    "df_reloaded.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d15b4460-0ff0-49bf-8f88-f51cba8e037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80273246292457.75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we want to calculate lost resources for each sample as a product of offline time and CPUs, and then we sum over all samples\n",
    "df_reloaded = df_reloaded.withColumn(\"lost\", df_reloaded[\"dtime\"]*df_reloaded[\"CPUs\"])\n",
    "total_lost = df_reloaded.agg(F.sum(\"lost\")).collect()[0][0]\n",
    "total_lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "451daaf0-2861-4c69-97d3-fb993abe3eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, in order to find percentage of lost resources, we want to find possible total power\n",
    "total_cpu = df_machines.select(\"machine_ID\", \"CPUs\").agg(F.sum(\"CPUs\")).collect()[0][\"sum(CPUs)\"]\n",
    "trace_bounds = df_machines.agg(\n",
    "    F.min(\"timestamp\").alias(\"start\"),\n",
    "    F.max(\"timestamp\").alias(\"end\")\n",
    ").collect()[0]\n",
    "total_time = trace_bounds[\"end\"] - trace_bounds[\"start\"]\n",
    "\n",
    "total_power = total_cpu * total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7e714f4-9fd4-4219-a6f2-755d66423ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of computational power lost due to maintenance: 0.1613%\n"
     ]
    }
   ],
   "source": [
    "percentage_lost = total_lost/total_power * 100\n",
    "print(f\"Percentage of computational power lost due to maintenance: {percentage_lost:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f6a55-b8a4-4905-af59-f3a7e789b7d8",
   "metadata": {},
   "source": [
    "**Here, we conclude that the total percentage of computational power lost due to mainenance is 0.16%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3deb58e-46ea-4dc4-ad8b-1cb80d12d6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95d2c4a2-c3fb-4d33-9a65-7cc2bcc84001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we need it for later, if not - delete :))\n",
    "\n",
    "# machine_att_schema = StructType([\n",
    "#     StructField('timestamp', LongType(), True),\n",
    "#     StructField('machine_ID', LongType(), True),\n",
    "#     StructField('attribute_name:', StringType(), True),\n",
    "#     StructField('attribute_value', StringType(), False),\n",
    "#     StructField('attribute_deleted:', BooleanType(), False),\n",
    "#     ])\n",
    "\n",
    "# df_machine_attributes = ss.read.csv(os.path.join(DATA_DIR,\"machine_attributes/*.csv.gz\"), schema=machine_att_schema)\n",
    "# df_machine_attributes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69f873-174b-41f8-a949-9c85ad04c6d6",
   "metadata": {},
   "source": [
    "### 3. Is there a class of machines, according to their CPU, that stands out with a higher maintenance rate, as compared to other classes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c89fea6-4fbe-4f29-a2b8-4df876196d61",
   "metadata": {},
   "source": [
    "- Here, by maintenance rate, we observe how frequently machines undergo maintenance (such as offline periods). We want to see if there is a class of machines (grouped by their CPU capacity) that experiences longer or more frequent maintenance periods compared to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fecf52d5-9a3f-4093-b7bc-5f90759ea079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|machine_ID|distinct_cpus|\n",
      "+----------+-------------+\n",
      "+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here, we check if every distinct machine can take only one value of CPU \n",
    "dfff = df_machines.groupBy(\"machine_ID\").agg(F.count_distinct(\"CPUs\").alias(\"distinct_cpus\"))\n",
    "dfff.filter(F.col(\"distinct_cpus\") > 1).show()\n",
    "# We conclude that only one CPUs value can be taken by one machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a860be0-d098-4e68-9df3-c30682ddda21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+----+---------------+----------+-----------+--------------+\n",
      "|machine_ID|event_type|         platform_ID|CPUs|memory_capacity|next_event|      dtime|          lost|\n",
      "+----------+----------+--------------------+----+---------------+----------+-----------+--------------+\n",
      "|         5|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  974247757| 4.871238785E8|\n",
      "|        10|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  998726348|  4.99363174E8|\n",
      "|        13|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  997280215| 4.986401075E8|\n",
      "|        23|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|  120851153|  6.04255765E7|\n",
      "|        26|         1|HofLGzk1Or/8Ildj2...| 0.5|         0.2493|         0|88666880740|4.433344037E10|\n",
      "+----------+----------+--------------------+----+---------------+----------+-----------+--------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# We will calculate maintenance rate as a total_offline_time per machine divided by total_time (already calculated). \n",
    "# We will use already calculated df_reloaded from previous task\n",
    "df_reloaded.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b634e33c-939d-41a3-9e9f-40ba4779dd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8860"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reloaded.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec2d5903-c111-42a5-a51c-6b222ec3c168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------------------+\n",
      "|machine_ID|CPUs|total_offline_time|\n",
      "+----------+----+------------------+\n",
      "|         5| 0.5|         974247757|\n",
      "|        10| 0.5|         998726348|\n",
      "|        13| 0.5|         997280215|\n",
      "|        23| 0.5|         120851153|\n",
      "|        26| 0.5|       88666880740|\n",
      "+----------+----+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_offline_times = df_reloaded.groupBy(\"machine_ID\", \"CPUs\").agg(F.sum(\"dtime\").alias(\"total_offline_time\"))\n",
    "df_offline_times.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c659e9b1-a65d-411c-bda4-b55bd6d0b6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------------------+---------------------------+\n",
      "|machine_ID|CPUs|total_offline_time|maintenance_rate_percentage|\n",
      "+----------+----+------------------+---------------------------+\n",
      "|         5| 0.5|         974247757|       0.038874504571689526|\n",
      "|        10| 0.5|         998726348|       0.039851251082934525|\n",
      "|        13| 0.5|         997280215|        0.03979354737921456|\n",
      "|        23| 0.5|         120851153|       0.004822211461137036|\n",
      "|        26| 0.5|       88666880740|         3.5379922980767815|\n",
      "+----------+----+------------------+---------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_offline_times = df_offline_times.withColumn(\n",
    "    \"maintenance_rate_percentage\", \n",
    "    F.col(\"total_offline_time\").cast(\"double\") * 100 / total_time)\n",
    "df_offline_times.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3258aa33-4ce0-413d-9de0-d73ceb058e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------------------+\n",
      "|CPUs|avg(maintenance_rate_percentage)|\n",
      "+----+--------------------------------+\n",
      "| 1.0|              0.7976476440387422|\n",
      "| 0.5|              1.2378912755606144|\n",
      "|0.25|              1.9150004966013052|\n",
      "+----+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_offline_times.groupBy(\"CPUs\").agg(F.avg(\"maintenance_rate_percentage\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc139e4-1832-48f3-bd1f-8e8146b83291",
   "metadata": {},
   "source": [
    "**From here, we conclude that machines with lowest CPU capacity (0.25) have the highest average maintenance rate (~1.92%)** <br>\n",
    " Therefore, the conclusion is that lower-CPU machines tend to have higher maintenance rates, which means they either undergo maintenance more frequently or for longer periods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d6a06f-ef1f-47b0-9820-350ab3713fa7",
   "metadata": {},
   "source": [
    "### 4. What is the distribution of the number of jobs/tasks per scheduling class? Comment on the results.\n",
    "\n",
    "Tasks and jobs can be resubmitted multiple times if they fail, therefore unique tasks are identified by their key (job_id) or composite key (job_id, task_index) and filtered with \".distinct()\" to ensure each task is counted only once, regardless of how many lifecycle events it generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101a9e4f-5802-47c8-b8b7-42a529a40db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for job events table\n",
    "job_events_schema = StructType([\n",
    "    StructField(\"timestamp\", LongType(), True),\n",
    "    StructField(\"missing_info\", StringType(), True),\n",
    "    StructField(\"job_id\", LongType(), True),\n",
    "    StructField(\"event_type\", IntegerType(), True),\n",
    "    StructField(\"user_name\", StringType(), True),\n",
    "    StructField(\"scheduling_class\", IntegerType(), True),\n",
    "    StructField(\"job_name\", StringType(), True),\n",
    "    StructField(\"logical_job_name\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d70c49-ee6c-4256-bffc-5cec31ed41d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+----------+--------------------+----------------+--------------------+--------------------+\n",
      "|   timestamp|missing_info|    job_id|event_type|           user_name|scheduling_class|            job_name|    logical_job_name|\n",
      "+------------+------------+----------+----------+--------------------+----------------+--------------------+--------------------+\n",
      "|772325004610|        NULL|6319958772|         1|ZpQmujQYX55FcN2RF...|               0|4iFTcCfph6IhTG3o4...|AmKr63lD9MIGXiAac...|\n",
      "|772325045338|        NULL|6319984350|         0|E+9U+J1Dicd5PJklb...|               1|UaXnrc6huaDo9qNtX...|Mz+7hmVdCFVQEwwuv...|\n",
      "|772325074372|        NULL|6319983180|         0|r/Al6kYJOwZITr6wi...|               2|ct6ai8SyqLEEEdgBS...|G/9E4AW9fSviXbmdF...|\n",
      "|772326178083|        NULL|6319984385|         0|F2+Gv53Pxd4KDRb/U...|               0|aPxb6dFdH8wZ2FTBC...|j25eTfDZ4FFHzd7p+...|\n",
      "|772327671789|        NULL|6319983180|         1|r/Al6kYJOwZITr6wi...|               2|ct6ai8SyqLEEEdgBS...|G/9E4AW9fSviXbmdF...|\n",
      "+------------+------------+----------+----------+--------------------+----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_job_events = ss.read.csv(os.path.join(DATA_DIR_L,\"job_events/*.csv.gz\"), schema=job_events_schema)\n",
    "df_job_events.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0dec0ea-b89b-49d2-a02e-d247a00b364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema for task events table\n",
    "task_events_schema = StructType([\n",
    "    StructField(\"timestamp\", LongType(), True),\n",
    "    StructField(\"missing_info\", StringType(), True),\n",
    "    StructField(\"job_id\", LongType(), True),\n",
    "    StructField(\"task_index\", IntegerType(), True),\n",
    "    StructField(\"machine_id\", LongType(), True),\n",
    "    StructField(\"event_type\", IntegerType(), True),\n",
    "    StructField(\"user_name\", StringType(), True),\n",
    "    StructField(\"scheduling_class\", IntegerType(), True),\n",
    "    StructField(\"priority\", IntegerType(), True),\n",
    "    StructField(\"req_cpu_cores\", DoubleType(), True),\n",
    "    StructField(\"req_ram\", DoubleType(), True),\n",
    "    StructField(\"req_local_disk\", DoubleType(), True),\n",
    "    StructField(\"different_machine_constraint\", BooleanType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb2aa2b-d774-41a7-92fb-266a438d2e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+----------+----------+----------+--------------------+----------------+--------+-------------+-------+--------------+----------------------------+\n",
      "|   timestamp|missing_info|    job_id|task_index|machine_id|event_type|           user_name|scheduling_class|priority|req_cpu_cores|req_ram|req_local_disk|different_machine_constraint|\n",
      "+------------+------------+----------+----------+----------+----------+--------------------+----------------+--------+-------------+-------+--------------+----------------------------+\n",
      "|767314028182|        NULL| 515042969|        15| 257406228|         1|/fk1fVcVxZ6iM6gHZ...|               2|       0|      0.01562|0.01553|      2.155E-4|                        NULL|\n",
      "|767314057755|        NULL|6319230508|        13|   6567628|         4|r/Al6kYJOwZITr6wi...|               0|       4|      0.06873|0.00795|      3.815E-5|                        NULL|\n",
      "|767314057799|        NULL|6319230508|         3|    902367|         4|r/Al6kYJOwZITr6wi...|               0|       4|      0.06873|0.00795|      3.815E-5|                        NULL|\n",
      "|767314057847|        NULL| 515042969|         3|      NULL|         5|/fk1fVcVxZ6iM6gHZ...|               2|       0|      0.01562|0.01553|      2.155E-4|                        NULL|\n",
      "|767314057850|        NULL| 515042969|         3|      NULL|         0|/fk1fVcVxZ6iM6gHZ...|               2|       0|      0.01562|0.01553|      2.155E-4|                        NULL|\n",
      "+------------+------------+----------+----------+----------+----------+--------------------+----------------+--------+-------------+-------+--------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_task_events = ss.read.csv(os.path.join(DATA_DIR_L,\"task_events/*.csv.gz\"), schema=task_events_schema)\n",
    "df_task_events.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f2c2d6-07a3-494e-9395-e3d8dd256c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+\n",
      "|scheduling_class|num_of_jobs|\n",
      "+----------------+-----------+\n",
      "|               1|       2977|\n",
      "|               3|        110|\n",
      "|               2|       2525|\n",
      "|               0|       3158|\n",
      "+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count number of unique jobs per scheduling class\n",
    "# groupBy creates groups based on scheduling_class\n",
    "# agg with count counts the number of job_ids in each group\n",
    "jobs_per_class = df_job_events.select(\"job_id\", \"scheduling_class\").distinct().groupBy(\"scheduling_class\").agg(F.count(\"job_id\").alias(\"num_of_jobs\"))\n",
    "\n",
    "jobs_per_class.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61360f99-055c-4db3-89eb-18616ef43be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8770"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate total number of unique jobs in the dataset\n",
    "# counts distinct job_ids across all events to get the absolute total\n",
    "total_jobs = df_job_events.select(\"job_id\").distinct().count()\n",
    "total_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9de4235-3d74-49a9-9425-0f12fde138f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+----------+\n",
      "|scheduling_class|num_of_jobs|percentage|\n",
      "+----------------+-----------+----------+\n",
      "|               1|       2977|      34.0|\n",
      "|               3|        110|       1.0|\n",
      "|               2|       2525|      29.0|\n",
      "|               0|       3158|      36.0|\n",
      "+----------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jobs_per_class.withColumn(\"percentage\", F.round((F.col(\"num_of_jobs\") / total_jobs) * 100)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da97555b-0ca6-4294-9ef3-e3dadc5d7daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+\n",
      "|scheduling_class|num_of_tasks|\n",
      "+----------------+------------+\n",
      "|               1|       32864|\n",
      "|               3|        2590|\n",
      "|               2|        9607|\n",
      "|               0|      285756|\n",
      "+----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count number of unique tasks per scheduling class\n",
    "# groupBy creates groups based on scheduling_class\n",
    "# agg with count counts the number of job_ids in combination with task_index in each group\n",
    "tasks_per_class = df_task_events.select(\"job_id\", \"task_index\", \"scheduling_class\").distinct().groupBy(\"scheduling_class\").agg(F.count(\"*\").alias(\"num_of_tasks\"))\n",
    "\n",
    "tasks_per_class.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61edf6d2-9670-46f5-bf8e-4a9fb477e8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330817"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate total number of unique jobs in the dataset\n",
    "# counts distinct combination of job_ids and task_index across all events to get the absolute total\n",
    "total_tasks = df_task_events.select(\"job_id\", \"task_index\").distinct().count()\n",
    "total_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81d75c03-68af-4f60-b7ae-8228a3f44628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+----------+\n",
      "|scheduling_class|num_of_tasks|percentage|\n",
      "+----------------+------------+----------+\n",
      "|               1|       32864|      10.0|\n",
      "|               3|        2590|       1.0|\n",
      "|               2|        9607|       3.0|\n",
      "|               0|      285756|      86.0|\n",
      "+----------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tasks_per_class.withColumn(\"percentage\", F.round((F.col(\"num_of_tasks\") / total_tasks) * 100)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab0cb54-6b73-4bcf-b0b5-9189a3ac3fca",
   "metadata": {},
   "source": [
    "**Scheduling Class Distribution:**\n",
    "- Class 0 (non-production): ~35% of jobs and 86% of task, this suggests non-production jobs tend to have many tasks per job\n",
    "- Class 1: 34% of jobs, 10% of tasks\n",
    "- Class 2: 29% of jobs, 3% of tasks  \n",
    "- Class 3 (most latency-sensitive): Only 1% of both jobs and tasks, indicating production workloads are a small but critical portion of the cluster\n",
    "\n",
    "**->** Non-production workloads (class 0) dominate task count and job count, suggesting they involve large-scale data processing jobs with many parallel tasks while, as the \"Google documentation\" notes, class 3 represents more latency-senstive tasks in production, being potentially short-lived and fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41354bb6-aac2-4b72-bdcd-fcd25cfba73e",
   "metadata": {},
   "source": [
    "### 5. Would you qualify the percentage of jobs/tasks that got killed or evicted as important? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4def37bf-a33d-4fa8-a03e-7025f4599281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define event type constants for readability\n",
    "EVICT = 2\n",
    "KILL = 5\n",
    "\n",
    "# Count unique jobs that were killed or evicted at least once across its lifecycle\n",
    "jobs_killed_evicted = (df_job_events.filter(F.col(\"event_type\").isin([EVICT, KILL])).select(\"job_id\").distinct().count())\n",
    "\n",
    "# Calculate percentage\n",
    "perc_jobs_killed_evicted = round(jobs_killed_evicted / total_jobs * 100)\n",
    "perc_jobs_killed_evicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8b76b03-5f2e-4e9f-bfb9-9806ba9bc87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3997"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Break down by event type \"KILL\"\n",
    "jobs_killed = (df_job_events.filter(F.col(\"event_type\").isin([KILL])).select(\"job_id\").count())\n",
    "jobs_killed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34ddc7cf-f50d-4d9e-a35b-f12579cc653f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Break down by event type \"EVICT\"\n",
    "jobs_evicted = (df_job_events.filter(F.col(\"event_type\").isin([EVICT])).select(\"job_id\").count())\n",
    "jobs_evicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6bb730f-778a-4c89-882a-7dfcda67ce3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count unique tasks that were killed or evicted at least once across its lifecycle\n",
    "tasks_killed_evicted = (df_task_events.filter(F.col(\"event_type\").isin([EVICT, KILL])).select(\"task_index\", \"job_id\").distinct().count())\n",
    "\n",
    "# Calculate percentage\n",
    "perc_tasks_killed_evicted = round(tasks_killed_evicted / total_tasks * 100)\n",
    "perc_tasks_killed_evicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f17562c5-a529-48ef-947c-9e74a5c7fa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138951"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Break down by event type \"KILL\"\n",
    "tasks_killed = (df_task_events.filter(F.col(\"event_type\").isin([KILL])).select(\"task_index\").count())\n",
    "tasks_killed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25a2567d-9f4e-4d57-b6ce-cc1186cdd97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83227"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Break down by event type \"EVICT\"\n",
    "tasks_evicted = (df_task_events.filter(F.col(\"event_type\").isin([EVICT])).select(\"task_index\").count())\n",
    "tasks_evicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f05dc-dd60-4078-ba5f-faaf3540b228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
